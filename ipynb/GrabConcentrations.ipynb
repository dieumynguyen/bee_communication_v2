{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import json\n",
    "from itertools import islice\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All params\n",
    "Q_list = [0.15]\n",
    "W_list = [0.15]\n",
    "D_list = [0.6]\n",
    "T_list = [0.00001, 0.0001, 0.001, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "wb_list = [5.0]\n",
    "decay_list = [18.0]\n",
    "seed_list = list(np.arange(0, 25))\n",
    "n_workers = 35\n",
    "\n",
    "param_sets = list(itertools.product(Q_list, W_list, D_list, T_list, wb_list, decay_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fiji script to grab concentration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_exp_dir = \"experiments/forConcentration_Q0.15_W0.15_D0.6_T0.0250_wb5.0_decay18.0_seed24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bee_path = os.path.join(base_exp_dir, \"bee_hist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bee_data = {}\n",
    "with h5py.File(bee_path, 'r') as infile:\n",
    "    for key, val in infile.items():\n",
    "        bee_data[key] = np.array(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bee_nums = np.unique(bee_data['bee_i'])\n",
    "bees = {}\n",
    "for bee_num in bee_nums:\n",
    "    idxs = np.where(bee_data['bee_i']==bee_num)\n",
    "    bee_x = bee_data['x'][idxs]\n",
    "    bee_y = bee_data['y'][idxs]\n",
    "    bee_state = bee_data['state'][idxs]\n",
    "    concentration = bee_data['concentration'][idxs]\n",
    "    threshold_met = bee_data['threshold_met'][idxs]\n",
    "    bees[bee_num] = {\"x\" : bee_x, \"y\" : bee_y, \"state\": bee_state,\n",
    "                    \"concentration\": concentration, \n",
    "                     \"threshold_met\" : threshold_met}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_time = len(bees[0]['state'])\n",
    "time_array = np.arange(0, sim_time)\n",
    "time_groups = [500, 500, 1000, 2000, 2000, 2000]  # intervals of above list\n",
    "it = iter(time_array)\n",
    "sliced = [list(islice(it, 0, i)) for i in time_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_concentration_dict = {}\n",
    "for bee_i, bee in enumerate(bees):\n",
    "    single_bee = bees[bee_i]\n",
    "    single_bee_state = single_bee['state']\n",
    "    single_bee_concentration = single_bee['concentration']\n",
    "    \n",
    "    timegroup_dict = {}\n",
    "    for g_i, g in enumerate(sliced):\n",
    "        # Filter scenting bees\n",
    "        state_mask = single_bee_state[g] == 1\n",
    "        \n",
    "        # Accumulate the concentrations - this length will vary\n",
    "        scenting_concentrations = single_bee_concentration[g][state_mask]\n",
    "        \n",
    "        # Make dictionary of concentrations for a single bee\n",
    "        timegroup_dict[f'timegroup_{g_i}'] = list(scenting_concentrations)\n",
    "     \n",
    "    total_concentration_dict[f'bee_{bee_i}'] = timegroup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(total_concentration_dict['bee_0']['timegroup_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Write json for 25 trials \n",
    "with open(f'concentration_data_{n_workers}.json', 'w') as fp:\n",
    "    json.dump(test_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Mock multiple trials\n",
    "# total = {\"A\": total_concentration_dict,\n",
    "#         \"B\": total_concentration_dict.copy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-fiji plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(wb, density):\n",
    "    filename = f\"worker_concentration/concentration_data/concentration_data_wb{wb:0.1f}_n{density}.json\"\n",
    "\n",
    "    with open(filename) as f:\n",
    "        concentration_data = json.load(f)\n",
    "\n",
    "    return concentration_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_lists(wb, optimal_T):\n",
    "    # Pick a random trial\n",
    "    random.seed(5)\n",
    "    random_trial = random.choice(seed_list)\n",
    "    \n",
    "    # Read in data for a given trial\n",
    "    total = concentration_data[f'Q0.15_W0.15_D0.6_T{optimal_T:0.4f}_wb{wb:0.1f}_decay18.0'][str(random_trial)]\n",
    "\n",
    "    # Concatenate lists across all bees\n",
    "    all_bees = {}\n",
    "    for bee_i, bee_lists in total.items():\n",
    "        for list_key, list_vals in bee_lists.items():\n",
    "            if list_key in all_bees:\n",
    "                all_bees[list_key] += list_vals\n",
    "            else:\n",
    "                all_bees[list_key] = list_vals\n",
    "    \n",
    "    return all_bees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_order(all_bees):\n",
    "    # Can customize merging method later\n",
    "    all_bees_merged = {\n",
    "    \"timegroup_0\": all_bees['timegroup_0'], # 0-500\n",
    "    \"timegroup_1\": all_bees['timegroup_1'], # 500-1000\n",
    "    \"timegroup_2\": all_bees['timegroup_2'] + all_bees['timegroup_3'], # 1000-4000\n",
    "    \"timegroup_3\": all_bees['timegroup_4'] + all_bees['timegroup_5'], # 4000-8000\n",
    "    }\n",
    "    \n",
    "    all_bees_ordered = collections.OrderedDict(reversed(list(all_bees_merged.items())))\n",
    "\n",
    "    return all_bees_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(time_array, all_bees_ordered, n, wb, density, optimalT, order):\n",
    "    for time_i, (timegroup, concentrations) in enumerate(all_bees_ordered.items()):\n",
    "        concentrations_array = np.array(concentrations)\n",
    "        x = np.mean(concentrations_array[:(len(concentrations_array)//n)*n].reshape(-1,n), axis=1)\n",
    "\n",
    "#         ax.hist(x, bins=100)\n",
    "        sns.distplot(x, kde=False, bins=100, \n",
    "                     hist_kws=dict(alpha=0.5, edgecolor=\"w\", linewidth=0.3),\n",
    "                     label=f\"{time[time_i+1]} - {time[time_i]}\", ax=order)\n",
    "        sns.despine()\n",
    "\n",
    "#     handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#     plt.legend(title=\"Time group\", handles=handles[::-1])\n",
    "#     plt.xlabel('Concentration')\n",
    "#     plt.ylabel('Count')\n",
    "#     plt.title(f'Concentration distribution \\nwb={wb}, density={density}, optimal threshold={optimalT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_dict = {\"35\": [0.001, 0.01],  # Optimal T for wb=0 and wb=5\n",
    "                \"70\": [0.001, 0.025],\n",
    "                \"140\": [0.025, 0.1]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  concentration_data = read_data(0, 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "n = 1\n",
    "time_array = [0, 500, 1000, 4000, 8000]\n",
    "time_array = time[::-1]\n",
    "\n",
    "for ax, (d_i, density) in zip(axs, enumerate(density_dict)):\n",
    "    for T_i, optimal_T in enumerate(density_dict[density]):\n",
    "        # Read data\n",
    "        wb = T_i * 5\n",
    "        \n",
    "        try:\n",
    "            concentration_data = read_data(wb, density)\n",
    "\n",
    "            # Concat bees for same time groups\n",
    "            all_bees = concat_lists(wb, optimal_T)\n",
    "\n",
    "            # Ordered data dict\n",
    "            all_bees_ordered = merge_order(all_bees)\n",
    "\n",
    "            # Plot histogram\n",
    "            plot_hist(time_array, all_bees_ordered, n, wb, density, optimal_T, axs[d_i])\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb = 0\n",
    "# density = 35\n",
    "# wb0_optimalT = density_dict[f'{density}'][0]\n",
    "\n",
    "# # Read data\n",
    "# concentration_data = read_data(wb, density)\n",
    "\n",
    "# # Concat bees for same time groups\n",
    "# all_bees = concat_lists(wb, wb0_optimalT)\n",
    "\n",
    "# # Ordered data dict\n",
    "# all_bees_ordered = merge_order(all_bees)\n",
    "\n",
    "# # Plot histogram\n",
    "# # time = [0, 500, 1000, 2000, 4000, 6000, 8000]\n",
    "# time_array = [0, 500, 1000, 4000, 8000]\n",
    "# time_array = time[::-1]\n",
    "# n = 1 # For average every nth element if needed\n",
    "# plot_hist(time_array, all_bees_ordered, n, wb, density, wb0_optimalT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(3)\n",
    "# random_trial = random.choice(seed_list)\n",
    "# random_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = concentration_data[f'Q0.15_W0.15_D0.6_T{wb0_optimalT:0.4f}_wb{wb:0.1f}_decay18.0'][str(random_trial)]\n",
    "# concentration_data['Q0.15_W0.15_D0.6_T0.0000_wb0.0_decay18.0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate lists across all bees\n",
    "# all_bees = {}\n",
    "# for bee_i, bee_lists in total.items():\n",
    "#     for list_key, list_vals in bee_lists.items():\n",
    "#         if list_key in all_bees:\n",
    "#             all_bees[list_key] += list_vals\n",
    "#         else:\n",
    "#             all_bees[list_key] = list_vals\n",
    "            \n",
    "# len(all_bees['timegroup_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_bees_merged = {\n",
    "#     \"timegroup_0\": all_bees['timegroup_0'], # 0-500\n",
    "#     \"timegroup_1\": all_bees['timegroup_1'], # 500-1000\n",
    "#     \"timegroup_2\": all_bees['timegroup_2'] + all_bees['timegroup_3'], # 1000-4000\n",
    "#     \"timegroup_3\": all_bees['timegroup_4'] + all_bees['timegroup_5'], # 4000-8000\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_bees_ordered = collections.OrderedDict(reversed(list(all_bees_merged.items())))\n",
    "# all_bees_ordered.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time = [0, 500, 1000, 2000, 4000, 6000, 8000]\n",
    "# time = [0, 500, 1000, 4000, 8000]\n",
    "# time = time[::-1]\n",
    "\n",
    "# n = 1\n",
    "# for time_i, (timegroup, concentrations) in enumerate(all_bees_ordered.items()):\n",
    "#     concentrations_array = np.array(concentrations)\n",
    "#     x = np.mean(concentrations_array[:(len(concentrations_array)//n)*n].reshape(-1,n), axis=1)\n",
    "\n",
    "#     sns.distplot(x, kde=False, bins=100, \n",
    "#                  hist_kws=dict(alpha=0.5, edgecolor=\"w\", linewidth=0.3),\n",
    "#                  label=f\"{time[time_i+1]} - {time[time_i]}\")\n",
    "#     sns.despine()\n",
    "\n",
    "# handles, labels = plt.gca().get_legend_handles_labels()\n",
    "# plt.legend(title=\"Time group\", handles=handles[::-1])\n",
    "# plt.xlabel('Concentration')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title(f'Concentration distribution - wb={wb}, density={density}, optimal threshold={wb0_optimalT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bees_all_trials = []\n",
    "\n",
    "# Loop over all trials/seeds and accumulate concentrations\n",
    "for t_key, t_val in total.items():\n",
    "    \n",
    "    # Loop over bees in an experiment (1 trial/seed)\n",
    "    # Concatenate lists across all bees\n",
    "    all_bees = {}\n",
    "    for bee_i, bee_lists in total_concentration_dict.items():\n",
    "        for list_key, list_vals in bee_lists.items():\n",
    "            if list_key in all_bees:\n",
    "                all_bees[list_key] += list_vals\n",
    "            else:\n",
    "                all_bees[list_key] = list_vals\n",
    "\n",
    "    all_bees_all_trials.append(all_bees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatentate lists across all trials\n",
    "all_trials = {}\n",
    "for trial in all_bees_all_trials:\n",
    "    for trial_i, trial_lists in total_concentration_dict.items():\n",
    "        for list_key, list_vals in trial_lists.items():\n",
    "            if list_key in all_trials:\n",
    "                all_trials[list_key] += list_vals\n",
    "            else:\n",
    "                all_trials[list_key] = list_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_merged = {\n",
    "    \"timegroup_0\": all_trials['timegroup_0'], # 0-500\n",
    "    \"timegroup_1\": all_trials['timegroup_1'], # 500-1000\n",
    "    \"timegroup_2\": all_trials['timegroup_2'] + all_trials['timegroup_3'], # 1000-4000\n",
    "    \"timegroup_3\": all_trials['timegroup_4'] + all_trials['timegroup_5'], # 4000-8000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_ordered = collections.OrderedDict(reversed(list(all_trials_merged.items())))\n",
    "all_trials_ordered.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = [0, 500, 1000, 2000, 4000, 6000, 8000]\n",
    "time = [0, 500, 1000, 4000, 8000]\n",
    "time = time[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "for time_i, (timegroup, concentrations) in enumerate(all_trials_ordered.items()):\n",
    "    concentrations_array = np.array(concentrations)\n",
    "    x = np.mean(concentrations_array[:(len(concentrations_array)//n)*n].reshape(-1,n), axis=1)\n",
    "\n",
    "    sns.distplot(x, kde=False, bins=100, \n",
    "                 hist_kws=dict(alpha=0.5, edgecolor=\"w\", linewidth=0.3),\n",
    "                 label=f\"{time[time_i+1]} - {time[time_i]}\")\n",
    "    sns.despine()\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(title=\"Time group\", handles=handles[::-1])\n",
    "plt.xlabel('Concentration')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Concentration distribution - wb={wb}, density={density}, optimal threshold={wb0_optimalT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
